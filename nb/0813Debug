# è¼‰å…¥æ‚¨çš„å°èªæ•¸æ“š
from datasets import load_dataset
data_file = "/content/drive/MyDrive/train_chatml.jsonl"
dataset = load_dataset("json", data_files=data_file, split="train")

print(f"âœ… è¼‰å…¥ {len(dataset)} ç­†å°èªæ•¸æ“š")
print(f"ğŸ“Š æ•¸æ“šæ¬„ä½: {dataset.column_names}")
print(f"ğŸ“‹ ç¯„ä¾‹: {dataset[0]}")


# æª¢æŸ¥æ•¸æ“šæ ¼å¼ä¸¦è™•ç†
if "text" in dataset.column_names:
    # æ‚¨çš„æ•¸æ“šæ˜¯ ChatML æ ¼å¼ï¼Œéœ€è¦è½‰æ›
    def convert_chatml_to_harmony(examples):
        texts = []
        for text in examples["text"]:
            import re
            
            # è§£æ ChatML
            system_match = re.search(r'<\|start\|>system\n(.*?)<\|end\|>', text, re.DOTALL)
            user_match = re.search(r'<\|start\|>user\n(.*?)<\|end\|>', text, re.DOTALL)
            assistant_match = re.search(r'<\|start\|>assistant\n(.*?)<\|end\|>', text, re.DOTALL)
            
            if system_match and user_match and assistant_match:
                system_content = system_match.group(1).strip()
                user_content = user_match.group(1).strip()
                assistant_content = assistant_match.group(1).strip()
                
                # æ·»åŠ æ¨ç†è¨­å®š
                enhanced_system = f"{system_content}\n\nReasoning: medium"
                
                conversation = [
                    {"role": "system", "content": enhanced_system},
                    {"role": "user", "content": user_content},
                    {"role": "assistant", "content": assistant_content}
                ]
                
                # è½‰æ›ç‚º harmony format
                harmony_text = tokenizer.apply_chat_template(
                    conversation, tokenize=False, add_generation_prompt=False
                )
                texts.append(harmony_text)
            else:
                texts.append(text)
        return {"text": texts}
    
    dataset = dataset.map(convert_chatml_to_harmony, batched=True)
    print("âœ… ChatML è½‰æ›ç‚º harmony format å®Œæˆ")

elif "messages" in dataset.column_names:
    # å¦‚æœæ˜¯æ¨™æº–æ ¼å¼ï¼Œä½¿ç”¨åŸå§‹è™•ç†
    from unsloth.chat_templates import standardize_sharegpt
    dataset = standardize_sharegpt(dataset)
    dataset = dataset.map(formatting_prompts_func, batched=True)

output_dir = "gpt-oss-20b-taiwanese-assistant",
